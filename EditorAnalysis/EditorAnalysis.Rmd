---
title: Replication for ...
bibliography: mybibfile.bib
output: 
  html_document:
    toc: yes
    toc_depth: 2
    number_section: yes
    theme: journal
    highlight: zenburn
    code_folding: hide
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  rticles::plos_article:
    csl: plos.csl
params:
  doc_refresh_data:
    value: no
    choices:
    - yes
    - no
  doc_debug:
    value: no
    choices:
    - yes
    - no
editor_options: 
  markdown: 
    wrap: 72
---
#Section 2 - Data Processing 
```{r label=setup, include=FALSE}
library(knitr)
## options for this document
doc_debug <- params$doc_debug
doc_refresh_data <- params$doc_refresh_data
knitr::opts_chunk$set("message" = doc_debug)
knitr::opts_chunk$set("warning" = doc_debug)
knitr::opts_chunk$set("tidy" = FALSE) # already tidyed using stylr
knitr::opts_chunk$set(autodep=TRUE)

## check for webshot if pdf output
doc_is_pdf <- 
  try (("pdf_document" %in% rmarkdown::all_output_formats(knitr::current_input())), silent=TRUE)
doc_is_pdf <- (doc_is_pdf == TRUE)
if (doc_is_pdf) {
  require("webshot")
  webshot::install_phantomjs()
}
# works in knit, but not in other environments
try(knitr::dep_auto())
```

```{r r-setup, include=FALSE}
# core libraries
library("tidyverse")
library("magrittr")
library("rlang")
library("purrr")
if (doc_debug) {
  require("tidylog")
}
library("gt")
library("crosstable")
library("ggplot2")
library("patchwork")

# Core EDA


# data retrieval
library("R.utils")
library("readxl")
library("fuzzyjoin")

# entity extraction and classification
library("humaniformat") # for first name extraction
library("gender")
library("genderdata") # install using devtools::install_github("lmullen/genderdata")
library("reticulate") # python geoentity extraction

# analysis
library("ggspatial") # needs libudunits2-dev -- sudo apt-get install libudunits2-dev
                     # sudo apt-get install gdal-bin proj-bin libgdal-dev libproj-dev
library("rgeos")
library("rnaturalearth")
library("rnaturalearthdata")
library("ggformula")
library("hhi")
library("tidymodels")
library("skimr")
library("DescTools")

# network analysis
library("DiagrammeR")
library("DiagrammeRsvg")
library("tidygraph")
library("igraph")
library("ggraph")
library("rsvg") # for exporting graph files -- silent failure from DiagrammeR without it
```

```{r fetch-data, include=FALSE}
###
### Retrieve raw data from sources
### 


##
## OpenEditors Data
## 

db.name <- "openeditors_combined.csv"
if (doc_refresh_data) {
  
   uris <- c(editor1.csv ="https://raw.githubusercontent.com/andreaspacher/openeditors/main/Output/editors1.csv",
            editor2.csv= "https://raw.githubusercontent.com/andreaspacher/openeditors/main/Output/editors2.csv")
   
   tmp.tbl <- NULL
   
   tmpfile <- tempfile(fileext=".csv")

   for (j in 1:length(uris)) {
     i <- uris[j]
     download.file(i,names(i))
     gEnc <- guess_encoding(names(i),n_max=-1)[[1]] # originally tried alternative encodings such as windows-1250, latin1, UTF8, "ISO-8859-1" as encodings,
     tmp.tbl %<>% bind_rows(read_csv(names(i),  locale = readr::locale(encoding = gEnc)))
   }
   write_csv(tmp.tbl,db.name)
   gzip(db.name)
}

editors_raw.tbl <- read_csv(paste(db.name,".gz",sep=""))


##
## DOAJ
##

db.name <- "doaj.csv"
if (doc_refresh_data) {
   download.file("https://doaj.org/csv",db.name)
   gzip(db.name)
}

doaj_raw.tbl <- read_csv(paste(db.name,".gz",sep=""))


##
## ERA
## 


db.name <- "era.xlsx" 
# linked from: "https://www.arc.gov.au/excellence-research-australia/era-2018-journal-list"
if (doc_refresh_data) {
  download.file("https://www.arc.gov.au/file/10549/download?token=Sbfb2a9n",db.name)
}
era_raw.tbl <- read_excel(db.name,2)
fieldcode_raw.tbl <- read_excel(db.name,3)
rm(db.name)
```
```{r data-top-fetch}
##
## TOP
## 

target.uri <- "https://osf.io/qatkz/download"
db.name <- "top_factor_raw.csv" 
if (doc_refresh_data) {
  download.file(target.uri,db.name)
}
top_factor_raw.tbl <- read_csv(db.name)
target.uri <- "https://osf.io/y2rr6/download"
db.name <- "top_signatory.csv" 
if (doc_refresh_data) {
  download.file(target.uri,db.name)
}
top_signatory_raw.tbl <- read_csv(db.name)
rm(db.name,target.uri)
```
```{r data-clean, include=FALSE}
### DOAJ
### normalize issn fields in preparation for merging
doaj.tbl <- doaj_raw.tbl
doaj.tbl %<>% pivot_longer(cols=c("Journal ISSN (print version)",
                  "Journal EISSN (online version)"),
                  values_to ="issn", names_to ="issn_type ", values_drop_na=TRUE) %>%
  rename(journal=`Journal title`,publisher=Publisher)
# NOTE -- checked that LICENSE, LCC not missing

### ERA
### normalize by issn, pack subject field
#TODO: find complementary source of discipline descriptions
era.tbl <- era_raw.tbl
era.tbl %<>% select(-c(starts_with("ERA"), ends_with("Name"), starts_with("Foreign")))
era.tbl %<>% unite("subjects",starts_with("FoR"),sep=",",na.rm=TRUE) %>%
  pivot_longer(starts_with("ISSN"), names_to = NULL, values_to = "issn", values_drop_na = TRUE ) %>% rename(journal="Title")

###
### Editors cleanup
editors_clean.tbl <- editors_raw.tbl
editors_clean.tbl %<>% select(-X1) 
editors_clean.tbl %<>% mutate(across(-c("issn","date","url"),as_utf8_character)) # clean unicode sequences
editors_clean.tbl %<>% mutate(across(-c("issn","date","url"),function(x)str_replace_all(x,'\\<.*\\>',''))) # strip unresolved escapes 
#TODO: convert latin-1 escape sequences to Unicode rather than strip them)
editors_clean.tbl %<>%
mutate(across(-c("issn","date","url"),str_squish)) # clean unicode sequences

### clean top data

top_factor_clean.tbl <- top_factor_raw.tbl %>%
  select(Journal, Issn, Publisher, Total) %>%
  rename(journal=Journal,issn=Issn,topScore=Total, publisher=Publisher)

top_signatory_clean.tbl <- top_signatory_raw.tbl %>%
  rename(journal="Journal Title", publisher="Publisher") %>%
  select(journal,publisher) %>% 
  mutate(issn=NA_character_)

## Some journals missing ISSN code
## Generate matching tables from era and doaj
era_issn_only.tbl <-  era.tbl %>% select("issn","journal") %>% group_by(journal) %>% slice_head(n=1) %>% rowwise() %>% mutate(
  journalStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " "))))
) %>% ungroup() %>% select(-journal)
# match to doaj
doaj_issn_only.tbl <- doaj.tbl %>% mutate(
 journalStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " ")))),
pubStd = str_to_lower(str_squish((str_replace_all(publisher, regex("\\W+"), " ")))),
 ) %>% select(journalStd,pubStd,issn)

```
```{r data-issnmatch, include=FALSE}

issnClean<-function(db) {
#TODO: experiment with publisher matching, journal duplicate title cleaning
  
  # standardize issn missing values
  db %<>% rowwise() %>% mutate(issn=na_if(issn,""))
  
  # wipe bogus ISSNS
  db %<>% rowwise() %>% mutate(issn=ifelse(str_detect(issn,"-"),issn,NA))
  
  # standardize journal title
  db %<>% rowwise() %>% mutate(
    journalStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " ")))),
    pubStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " ")))), 
  )

    # exact join to era
  joinedissn <- db %>% ungroup %>% filter(is.na(issn)) %>%
    select(journalStd) %>% 
    left_join(era_issn_only.tbl,by=("journalStd")) %>%
    filter(!is.na(issn)) %>% 
    select(journalStd,issn)
  
  db  %<>% left_join(joinedissn, by=("journalStd")) %>%
    unite("issn","issn.x","issn.y",na.rm=TRUE) %>% 
    group_by(journal) %>% slice_head() %>% ungroup %>%
     mutate(issn=na_if(issn,""))
  
  # exact join to doaj
  
  joinedissn <- db %>% ungroup %>% filter(is.na(issn)) %>%
    select(journalStd) %>% 
    left_join(doaj_issn_only.tbl %>% select(-pubStd),by=("journalStd")) %>%
    filter(!is.na(issn)) %>% select(journalStd,issn)
   
  db  %<>% left_join(joinedissn, by=("journalStd")) %>%
    unite("issn","issn.x","issn.y",na.rm=TRUE) %>% 
    group_by(journal) %>% slice_head() %>% ungroup %>%
     mutate(issn=na_if(issn,""))
  
  # fuzzy join to era
  
  joinedissn <- 
    db %>% ungroup %>% filter(is.na(issn)) %>%
    select(journalStd) %>% 
    stringdist_left_join( 
      era_issn_only.tbl ,
      by=c("journalStd"), 
      ignore_case=TRUE,
      distance_col="dist",
      max_dist=3
    ) %>% 
    rename(journalStd=journalStd.x) %>%
    filter(!is.na(issn)) %>% 
    mutate(len=str_length(journalStd),distp=(len-dist)/len) %>% arrange(desc(distp)) %>%
    group_by(journalStd) %>%
    slice_max(distp) %>% 
    slice_head() %>% 
    ungroup() %>%
    filter(distp >= .95) %>%
    select(journalStd,issn)

  db  %<>% left_join(joinedissn, by=("journalStd")) %>%
    unite("issn","issn.x","issn.y",na.rm=TRUE) %>% 
    group_by(journal) %>% slice_head() %>% ungroup %>%
    mutate(issn=na_if(issn,""))
  
  # fuzzy join to doaj
  
  joinedissn <- 
    db %>% ungroup %>% filter(is.na(issn)) %>%
    select(journalStd) %>% 
    stringdist_left_join( 
      doaj_issn_only.tbl %>% select(-pubStd) ,
      by=c("journalStd"), 
      ignore_case=TRUE,
      distance_col="dist",
      max_dist=3
    ) %>% 
    rename(journalStd=journalStd.x) %>%
    filter(!is.na(issn)) %>% 
    mutate(len=str_length(journalStd),distp=(len-dist)/len) %>% arrange(desc(distp)) %>%
    group_by(journalStd) %>%
    slice_max(distp) %>% 
    slice_head() %>% 
    ungroup() %>%
    filter(distp >= .95) %>%
    select(journalStd,issn)

  db  %<>% left_join(joinedissn, by=("journalStd")) %>%
    unite("issn","issn.x","issn.y",na.rm=TRUE) %>% 
    group_by(journal) %>% slice_head() %>% ungroup %>%
    mutate(issn=na_if(issn,""))
  
  db %>% select(-journalStd,-pubStd)
}

#debug(issnClean)
top_factor_clean.tbl %>% filter(is.na(issn)) %>% count() %>% pull
top_factor.tbl <- issnClean(top_factor_clean.tbl)
top_factor.tbl %>% filter(is.na(issn)) %>% count() %>% pull
top_factor.tbl %<>% filter(!is.na(issn))
top_signatory_clean.tbl %>% filter(is.na(issn)) %>% count() %>% pull
top_signatory.tbl <- issnClean(top_signatory_clean.tbl)
top_signatory.tbl %>% filter(is.na(issn)) %>% count() %>% pull
top_signatory.tbl %<>% filter(!is.na(issn)) %>% mutate(topSign=TRUE)

noissn_ed.tbl <- editors_clean.tbl %>%  filter(is.na(issn)) %>% select(c("journal","publisher","issn")) %>% group_by(journal,publisher) %>% 
  slice_head() %>% ungroup

duplicate_journals <- noissn_ed.tbl %>% group_by(journal) %>% count() %>% filter(n>1)
if (nrow(duplicate_journals>0))  { 
  print(paste("duplicate journal names", nrow(duplicate_journals)))
}
print(nrow(noissn_ed.tbl))
noissn_ed.tbl %<>% issnClean() 
noissn_ed.tbl %>% filter(is.na(issn)) %>% count() %>% pull
noissn_ed.tbl %<>% filter(!is.na(issn)) %>% 
  group_by(journal,publisher) %>% slice_head(n=1) %>% ungroup

editors_clean.tbl %>% filter(is.na(issn)) %>% count() %>% pull
editors_issn.tbl <- editors_clean.tbl %>% left_join(noissn_ed.tbl,by=c("publisher","journal")) %>% unite("issn","issn.x","issn.y",na.rm=TRUE) %>%
mutate(issn=na_if(issn,""))  
editors_issn.tbl %>% filter(is.na(issn)) %>% count() %>% pull

rm(noissn_ed.tbl,duplicate_journals )
```
```{r data-merge}
### Join editors with journal information
editors_join.tbl <- editors_issn.tbl

if (!doc_debug) {
    rm("editors_raw.tbl","era_raw.tbl")
}

# note if journal doesn't appear in doaj, we define it as not having an open license
# this applies even where there the issn is missing because we've already tried to repair
# issn by matching against the doaj database journal title

editors_join.tbl %<>% left_join(doaj.tbl %>% select(issn,"Journal license"), by="issn") %>% rename(license="Journal license")  %>% rowwise() %>%  mutate(license = ifelse(is.na(license),"none",license),  IND_openlicense=(license!="none"))

editors_join.tbl %<>% left_join(era.tbl %>% select(issn,subjects), by=c("issn"))

editors_join.tbl %<>% left_join(top_factor.tbl %>% select(issn,topScore) ,by=c("issn"))
editors_join.tbl %<>% left_join(top_signatory.tbl %>% select(issn,topSign) ,by=c("issn")) %>% rowwise()  %>% mutate(topSign=ifelse(is.na(topSign),is.na(issn),topSign))
```



-   Fields parsed
-   first name: extracted from full name (using humaniformat), with
    preprocessing to remove titled ("Dr.","Professor.")
-   county - parsed from affiliation, validated with gazetteer

```{r data-parse-names}
### extract given names for gender analysis
editors_parse.tbl <- editors_join.tbl 
if (!doc_debug) {
    rm("editors_clean.tbl")
}


# first_name() fails on empty string, wrap it
safe_first_name <- possibly(first_name, otherwise="")
safe_last_name <- possibly(last_name, otherwise="")
safe_middle_name <- possibly(middle_name, otherwise="")
safe_format_reverse <- possibly(format_reverse, otherwise="")


# remove honorifics
editors_parse.tbl %<>% 
  rowwise() %>% 
  mutate(LS_FULLNAME = ifelse(str_to_upper(editor)==editor,str_to_title(editor),editor)) %>%
  mutate(LS_FULLNAME =
           str_squish(str_replace_all(`LS_FULLNAME`, '(Dr\\.)|(Prof\\.)|(Doctor )|(Professor )|(Dr )|(Prof )| PhD| Ph.D.| MSc| PharmD| PsyD| MPhil| MEd| ScD|\\*', '' ) ) ) %>% 
  mutate(
    LS_FULLNAME = ifelse(is.na(LS_FULLNAME),NA,  paste(
  setdiff(
  str_replace_all(
    str_squish(
      unlist(
        str_split(LS_FULLNAME,",")
        )
      ) , 
    '^([A-Z]|\\-|\\.){3,}$',''),c("")),
  collapse=", ")
  )
  )

editors_parse.tbl %<>% 
  rowwise() %>% 
  mutate(LS_FULLNAME=ifelse(str_detect(LS_FULLNAME,"^[:alpha:]+[:space:]*,[:space:]*([:alpha:]|\\.)+$"),safe_format_reverse(LS_FULLNAME),LS_FULLNAME)) %>%
  mutate(
    LS_INSTITUTION = head(unlist(str_split(affiliation,",")),n=1),
    LS_FIRSTNAME = safe_first_name(`LS_FULLNAME`),
    LS_LASTNAME = safe_last_name(`LS_FULLNAME`),
    LS_MIDDLENAME = safe_middle_name(`LS_FULLNAME`),
  )
                                                                  
#post-cleanup
# single letter, or ending with a period of comma, is a last name, or abbreviation rather than first
editors_parse.tbl %<>% rowwise() %>% mutate(LS_GIVENNAME = case_when(
  LS_FIRSTNAME=="" ~ NA_character_,
  str_length(LS_FIRSTNAME)==1 ~ NA_character_,
  str_detect(LS_FIRSTNAME,'.*(\\.|\\,)') ~ NA_character_,
  TRUE ~ LS_FIRSTNAME
))
```
# Section 3- Methods
```{r data-parse-countries}
### extract country using geotext
#TODO: check IRR 
editors_parse_c.tbl <- editors_parse.tbl 
if (!doc_debug) {
    rm("editors_join.tbl")
}

## setup geotext
if (doc_refresh_data & doc_debug) {
  py_install(packages="geotext") 
}

wrap_python <- function (module,importfun) {
  core_fun <- import(module)
  safe_fun <- possibly(core_fun[importfun], otherwise=NA)
  safe_list_fun <- function (xlist,...) {
    return( 
      sapply(xlist, safe_fun, ...,
             simplify=TRUE, USE.NAMES=FALSE )
    )
  }
}

geotext<- wrap_python("geotext","GeoText") 

## geotext and check against naive parsing

affiliations.tbl <- editors_parse_c.tbl %>% group_by(`affiliation`) %>% slice_head(n=1) %>% ungroup() %>% select(`affiliation`)

affiliations.tbl %<>% rowwise() %>% mutate(LS_COUNTRY_CHK = tail(unlist(str_split(`affiliation`,',')),n=1))

affiliations.tbl %<>% rowwise() %>% mutate( 
  LS_COUNTRY_G = names(geotext(str_to_title(`LS_COUNTRY_CHK`))[[1]]["country_mentions"])[1] 
  )

affiliations.tbl %<>% rowwise() %>% mutate(LS_COUNTRY_CHK2 = str_to_title(LS_COUNTRY_CHK),
          LS_COUNTRY = case_when(
  !is.na(LS_COUNTRY_G) ~ LS_COUNTRY_G, 
  str_detect(LS_COUNTRY_CHK,"USA") ~ "US",
  str_detect(LS_COUNTRY_CHK,"UK") ~ "GB",
  str_detect(LS_COUNTRY_CHK2,"Netherlands") ~ "NL",
  str_detect(LS_COUNTRY_CHK2,"Russia") ~ "RU",
  str_detect(LS_COUNTRY_CHK2,"Viet Nam") ~ "VN",
  str_detect(LS_COUNTRY_CHK2,"Korea") ~ "KR",
  str_detect(LS_COUNTRY_CHK2,"Emirates") ~ "AE",
  str_detect(LS_COUNTRY_CHK,"UAE") ~ "AE",
  str_detect(LS_COUNTRY_CHK,"CHN") ~ "CN",
  str_detect(LS_COUNTRY_CHK2,"Brasil") ~ "BR",
  str_detect(LS_COUNTRY_CHK2,"Scotland") ~ "GB",
  str_detect(LS_COUNTRY_CHK2,"Singapore") ~ "SG",
  str_detect(LS_COUNTRY_CHK2,"Trinidad") ~ "TT",
  str_detect(LS_COUNTRY_CHK,"KSA") ~ "SA",
  str_detect(affiliation,"Korea") ~ "KR",
  TRUE ~ ""
))

editors_parse_c.tbl %<>% left_join(affiliations.tbl  %>% select("affiliation","LS_COUNTRY"), by=c("affiliation"))
```
```{r code-roles}
    editors_full.tbl <- editors_parse_c.tbl
    if (!doc_debug) {
        rm("editors_parse.tbl")
    }

    ## role coding
    role.tbl <- editors_full.tbl %>% select(`role`) %>%  group_by(role) %>% count()  %>% mutate (`rolec`=str_to_title(role))

    role.tbl %<>% rowwise() %>%
    mutate(CAT_ROLE_FORMER = str_detect(rolec,'(Former)|(Past)|(Emerit)'))

    role.tbl %<>% rowwise() %>%
      mutate(CAT_ROLE = case_when(
        is.na(rolec) ~ "",
      str_detect(rolec,"(In Chief)|(In-Chief)") ~ "chief",
      str_detect(rolec,"Field Chief Editor") ~ "chief", # Frontiers nomenclature for chief editor
      str_detect(rolec,"Founding Editor") ~ "chief",
      str_detect(rolec,"Specialty Chief Editor") ~ "editor", # frontiers nomenclature of section editor
      str_detect(rolec,"Associate Editor") ~ "editor",
      str_detect(rolec,"Assistant Editor") ~ "editor",
      str_detect(rolec,"Senior Editor") ~ "editor",
      str_detect(rolec,"Book Review") ~ "editor",
      str_detect(rolec,"Academic Editor") ~ "review",
      str_detect(rolec,"Review Editor") ~ "review",
      str_detect(rolec,"Editorial Board") ~ "review",
      str_detect(rolec,"Advisory Board") ~ "review",
      str_detect(rolec,"Advisory Committee") ~ "review",
        str_detect(rolec,"Scientific Committee") ~ "review",
      str_detect(rolec,"Scientific Advisor") ~ "review",
      str_detect(rolec,"Commissioning Editor") ~ "",
      str_detect(rolec,"Editorial Office") ~ "", # Emerald uses this for publisher business
      str_detect(rolec,"Editor") ~ "editor",
        str_detect(rolec,"Advisory") ~ "review",
      str_detect(rolec,"Review") ~ "review",
      str_detect(rolec,"Board") ~ "review",
      str_detect(rolec,"Academic") ~ "review",
      str_detect(rolec,"Members") ~ "review",
      TRUE ~ ""
    ))

    editors_full.tbl %<>% left_join(role.tbl %>% select(role,CAT_ROLE,CAT_ROLE_FORMER),by=c("role"))
    rm(role.tbl)
    ```

```{r gender_imputation, cache=TRUE, dependson=knitr::dep_auto()}
### impute gender based on name
gender_meth_list <- c("ipums","ssa","kantrowitz")


# gender is buggy and inconsistent can fail on genderize method, return inconsistent number of columns depending on method, return duplicate rows -- 
# so standardize it with wrappers

#NOTE: genderizer method has an API limit of 1000/day -- unless a purchased API key is supplied
# and gender() provides no way of passing in API key, even if you have one -- so ran this as
# a one-time job, and load results from csv

safer_gender <- function(x, ...) {
  rate <- rate_backoff(pause_base = 0.1, pause_min = 0.005, max_times = 4)
  insistent_gender<-insistently(gender,rate)
  
  
  safe_gender <- possibly(insistent_gender, otherwise=NULL)
  rsg <- safe_gender(x, ...)
  if (is.null(nrow(rsg)) || nrow(rsg)<1) {
    tmp <- tibble(name=NA,gender=NA,proportion_male=NA_real_)
  } else if (all(c("gender","proportion_male") %in% colnames(rsg))) {
    tmp <- rsg %>% select(name,gender,proportion_male)
  } else if (c("gender") %in% colnames(rsg)) {
    tmp <- rsg %>% select(name,gender) %>% mutate(proportion_male=NA_real_)
  } 
  
  tmp %<>% group_by(name) %>% slice_head(n=1) %>% ungroup()
  
  rv <- left_join(tibble(name=x),tmp,by=c("name"))
  rv %<>% rowwise() %>% mutate(proportion_male = case_when (
    is.na(proportion_male)==FALSE ~ proportion_male,
    gender=="male" ~ 1,
    gender=="female" ~ 0,
    is.na(gender) ~ NA_real_,
    TRUE ~ .5
  )) %>% ungroup()
  rv
  
}



#if (doc_refresh_data){
if(TRUE) {
  nms.tbl <-  editors_full.tbl %>%
    filter(!is.na(LS_GIVENNAME)) %>%
    group_by(`LS_GIVENNAME`) %>%
    count(sort=TRUE)
  
  nmtmp <- nms.tbl %>% ungroup() %>% select(LS_GIVENNAME) %>%
     pull()
  

    nmsgender.tbl <- map_dfr(gender_meth_list,
                             ~ safer_gender(nmtmp, method=.x) %>% mutate(method=.x))
    
    nms_gender_genderize.tbl <- read_csv("genderize_bulk_api_results.csv")
    nms_gender_genderize.tbl %<>% select(LS_GIVENNAME,gender,genderProbability) %>%
      mutate(method="genderize",
             proportion_male = ifelse(gender=="male",genderProbability,1-genderProbability)) %>%
      select(-genderProbability) %>% rename(name=LS_GIVENNAME)
    
    nmsgender.tbl %<>% bind_rows(nms_gender_genderize.tbl)
    nmsgender.tbl %<>%  mutate( gender =case_when( 
        is.na(gender) ~ NA_character_,
        gender=="male" ~"male",
        gender=="female" ~"female",
        TRUE ~ NA_character_) ) %>% 
        mutate(proportion_male= ifelse(is.na(gender),NA_real_,proportion_male))
  
  
  save(nmsgender.tbl,file="nms.RData")
} else {
  load( file="nms.RData")
  
}
#rm(list=c("nmtmp","nms.tbl"))

#TODO: missing genderize ids, appendix with alternative SSA/IPUMS scores

gender_meth <- "genderize"
bltmp<- nmsgender.tbl %>% filter(method==gender_meth) %>% select(name,gender,proportion_male) %>% rename(LS_GIVENNAME=name,LS_GENDER=gender,PERCENT_PROPENSITY_MALE=proportion_male)

editors_full.tbl %<>% left_join(nmsgender.tbl %>% filter(method==gender_meth) %>% select(name,gender,proportion_male) %>% rename(LS_GIVENNAME=name,LS_GENDER=gender,PERCENT_PROPENSITY_MALE=proportion_male),
                                      by=c("LS_GIVENNAME"))
edcsv.file <- "editors_full.csv.gz"
write_csv(editors_full.tbl,edcsv.file)
```

```{r analysis-prep-editors}
if (!doc_debug) {
    rm("editors_parse_c.tbl")
}

editors_analysis.tbl <- editors_full.tbl
editors_analysis.tbl %<>% rowwise() %>%
  mutate(FAC_TOP = case_when(
    ((is.na(topScore)==FALSE) && (topScore > 0)) ~ "score 1+",
    (is.na(topScore)==FALSE) ~ "score 0",
    ((is.na(topSign)==FALSE) && topSign) ~ "signatory",
    (is.na(topSign)==FALSE) ~ "no TOP",
  )) %>% ungroup() %>%
  mutate(FAC_TOP= factor(FAC_TOP, levels=c("no TOP", "signatory", "score 0", "score 1+"), ordered=TRUE ))

## create an internal id for each person in the data

# person_ids.tbl <- editors_analysis.tbl %>% 
#   group_by(editor,affiliation) %>% 
#   filter(!is.na(editor)) %>%
#   filter(!is.na(affiliation)) %>% 
#   count() %>% ungroup() %>% 
#   filter(n>1) %>% 
#   mutate(editor_id = seq_len(n()))

person_ids_full.tbl <- editors_analysis.tbl %>% 
  filter(!is.na(LS_FULLNAME)) %>%
  group_by(LS_FULLNAME,LS_INSTITUTION) %>%
  count() %>% ungroup() %>% 
  mutate(editor_id = seq_len(n())) %>%
  ungroup()

person_ids.tbl <- person_ids_full.tbl %>% select(-n)

editors_analysis.tbl %<>% left_join(person_ids.tbl,by=c("LS_FULLNAME","LS_INSTITUTION"))

editors_analysis.tbl %<>% mutate (
  FAC_ROLE = factor(CAT_ROLE, levels=c("review","editor","chief"), ordered=TRUE ),
  IND_MALE= LS_GENDER, 
  IND_MALE = na_if(LS_GENDER,"either"),
  IND_MALE = na_if(IND_MALE,""),
  LS_COUNTRY = na_if(LS_COUNTRY,""),
  IND_MALE = IND_MALE=="male",
  ) %>% 
  rename( NM_JOURNAL=journal, CAT_PUBLISHER=publisher, LS_SUBJECTS = subjects, IND_OPEN = IND_openlicense, NM_EDID=editor_id) %>%
  select(NM_JOURNAL, CAT_PUBLISHER,FAC_TOP, IND_MALE, IND_OPEN, LS_COUNTRY, LS_SUBJECTS, FAC_ROLE, FAC_TOP,NM_EDID,PERCENT_PROPENSITY_MALE) %>% ungroup()
```
```{r analysis-prep-journals}
### construct editorial board characteristics
journal_board_analysis.tbl <- editors_analysis.tbl %>% 
  group_by(NM_JOURNAL,FAC_ROLE) %>% 
  summarise(
    CAT_PUBLISHER = head(CAT_PUBLISHER,n=1),
    LIST_SUBJECTS = unique(str_split(head(LS_SUBJECTS,n=1),',')),
    N_SUBJECTS = ifelse(head(LS_SUBJECTS,n=1)=="MD", 4, length(unlist(LIST_SUBJECTS))), # ERA counts 3 subjects, plus "MD" for multidisciplinary 
  IND_OPEN= head(IND_OPEN,n=1),
  FAC_TOP=  head(FAC_TOP,n=1),
  N_BRD_SIZE = n(),
  LIST_EDID = list(na.omit(NM_EDID)),
  LIST_ROLEGROUP_COUNTRIES = list(LS_COUNTRY),
  N_ROLEGROUP_COUNTRIES= length(unique(unlist(LIST_ROLEGROUP_COUNTRIES))),
  N_ROLEGROUP_COUNTRIES = na_if(N_ROLEGROUP_COUNTRIES,0),
  PERCENT_ROLEGROUP_MALE = mean(IND_MALE,na.rm=TRUE),
  PROPENSITY_ROLEGROUP_MALE = mean(PERCENT_PROPENSITY_MALE,na.rm=TRUE)
) %>% 
  rowwise() %>%
  mutate(LIST_EDID = ifelse(length(unlist(LIST_EDID))==0, NA, LIST_EDID),
         ) %>%
  unnest(LIST_ROLEGROUP_COUNTRIES) %>% 
  rename(COUNTRIES=LIST_ROLEGROUP_COUNTRIES) %>% 
  nest(LIST_ROLEGROUP_COUNTRIES=c(COUNTRIES)) %>%
  ungroup()

# add labeled major subjects

journal_board_analysis.tbl %<>% 
  unnest(LIST_SUBJECTS) %>% 
  rename(CAT_SUBJECT=LIST_SUBJECTS) %>% 
  mutate(CAT_MAJSUBJECT=substr(CAT_SUBJECT,1,2)) %>%
  left_join(fieldcode_raw.tbl,by=c(CAT_MAJSUBJECT="FoR Code")) %>% 
  rename(LABEL_SUBJECT="FoR Description") %>% 
  mutate(LABEL_SUBJECT= ifelse(str_starts(CAT_MAJSUBJECT,"MD"),"Multidisciplinary",LABEL_SUBJECT)) %>% 
  nest(LIST_SUBJECTS=c(CAT_SUBJECT,LABEL_SUBJECT,CAT_MAJSUBJECT))

journal_analysis.tbl <- journal_board_analysis.tbl %>%
  filter(!is.na(FAC_ROLE)) %>%
  group_by(NM_JOURNAL) %>%
  mutate(N_JRN_SIZE=sum(N_BRD_SIZE)) %>%
  mutate(LIST_EDID=list(unique( na.omit(unlist(LIST_EDID))))) %>%
  select(-N_ROLEGROUP_COUNTRIES,-PERCENT_ROLEGROUP_MALE, -LIST_ROLEGROUP_COUNTRIES, -N_BRD_SIZE, -FAC_ROLE) %>% 
  slice_head()  %>%
  ungroup() %>% 
  mutate(NM_JOURNALID=seq_len(n()))

# compute HHI
countries_to_hhi<-function(x) {
  safe_hhi <- possibly(hhi,otherwise=NA)
  counts <- 
    x %>% group_by(COUNTRIES) %>% 
    count() %>% na.omit %>%
    ungroup() %>% mutate(total=sum(n)) %>%
    rowwise() %>% transmute(s=round((n*100)/total)) %>% data.frame()
  
  if (nrow(counts)==0) {
        retval <- NA
  } else {
    retval <- suppressWarnings( safe_hhi(counts)/10000 )
  }
  retval
}

journal_board_analysis.tbl %<>% rowwise() %>% mutate(PERCENT_HHI = countries_to_hhi(LIST_ROLEGROUP_COUNTRIES))

```
```{r network-gen}
#TODO: edge weights by number of shared editors

edges.df <- journal_analysis.tbl %>% 
  select(LIST_EDID,NM_JOURNALID) %>% 
  unnest(LIST_EDID)

edges.df %<>% left_join(edges.df,by=c("LIST_EDID")) %>%
  group_by(NM_JOURNALID.x,NM_JOURNALID.y) %>%
  slice_head() %>% 
  select(-LIST_EDID) %>% 
  rowwise() %>% 
  filter(NM_JOURNALID.x!=NM_JOURNALID.y) %>% 
  rename(to=NM_JOURNALID.x, from=NM_JOURNALID.y) %>%
  ungroup() %>%
  mutate(id=seq_len(n()),rel="shared editor") %>%
  relocate(id,to,from)

# remove duplicate edges for undirected graph
edges_undirected.df <- edges.df %>% rowwise () %>%
  mutate(tmpkey=paste(sort(c(to,from)),collapse="-")) %>%
  group_by(tmpkey) %>%
  slice_head() %>%
  ungroup() %>%
  select(-tmpkey)

nodes.df <- journal_analysis.tbl
linked_nodes <- edges.df %>% select(to,from) %>%
  pivot_longer(cols=c(to,from),names_to=NULL,values_to="id") %>% 
  group_by(id) %>% slice_head() %>% ungroup()
nodes_small.df <- nodes.df %>% 
  semi_join( linked_nodes,by=c("NM_JOURNALID"="id"))

journals.graph <-create_graph(
  nodes_df = journal_analysis.tbl %>% 
    mutate(id=NM_JOURNALID,label=id) %>% relocate(id,label) , 
  edges_df = edges.df, 
  graph_name="Journal Board Sharing",
 directed=TRUE)

journals_linked.graph <-create_graph(
  nodes_df = nodes_small.df %>% 
    mutate(id=NM_JOURNALID,label=id) %>% relocate(id,label) , 
  edges_df = edges.df, 
  graph_name="Journal Board Sharing - Connected Only",
  directed=TRUE)

journals_linked.tgraph <-  as_tbl_graph(to_igraph(journals_linked.graph))
journals.tgraph <-  as_tbl_graph(to_igraph(journals.graph))
```
```{r save-checkpoint}
save.image(file="checkpoint.RData")
```

## Table: Distribution of journals by publisher
```{r load-checkpoint}
load(file="checkpoint.RData")
```
```{r ggplot-theming}
library(ggthemes)
library(tvthemes)
library(ggsci)
library(extrafont)

import_simpsons() ## shows location of font for installation
loadfonts()
theme_set(theme_simpsons(text.font="Akbar"))
theme_set(theme_fivethirtyeight(base_size = 12, base_family = "sans"))
theme_set(theme_tufte(base_size = 11, base_family = "serif", ticks = TRUE))


scale_color_my_cont <- function(...) {
  #tvthemes::scale_color_simpsons(...,type="continuous")
    scale_color_continuous_tableau( ...)

}
scale_color_my_dis <- function(...) {
  #tvthemes::scale_color_simpsons(...,type="discrete")
    scale_color_tableau(...)
}
scale_fill_my_cont <- function(...) {
  #tvthemes::scale_fill_simpsons(...,type="continuous")
    scale_fill_continuous_tableau( ...)

}
scale_fill_my_dis <- function(...) {
  #tvthemes::scale_fill_simpsons(...,type="discrete")
    scale_fill_tableau( ...)

}

options(ggplot2.continuous.colour=scale_color_my_cont)
options(ggplot2.continuous.fill=scale_fill_my_cont)
options(ggplot2.binned.colour=scale_color_my_cont)
options(ggplot2.binned.fill=scale_fill_my_cont)
options(ggplot2.discrete.colour=scale_color_my_dis)
options(ggplot2.discrete.fill=scale_fill_my_dis)


gt_theme_538 <- function(data,...) {
  data %>%
  opt_all_caps()  %>%
  opt_table_font(
    font = list(
      google_font("Chivo"),
      default_fonts()
    )
  ) %>%
    tab_style(
      style = cell_borders(
        sides = "bottom", color = "transparent", weight = px(2)
      ),
      locations = cells_body(
        columns = everything(),
        # This is a relatively sneaky way of changing the bottom border
        # Regardless of data size
        rows = nrow(data$`_data`)
      )
    )  %>% 
  tab_options(
    column_labels.background.color = "white",
    table.border.top.width = px(3),
    table.border.top.color = "transparent",
    table.border.bottom.color = "transparent",
    table.border.bottom.width = px(3),
    column_labels.border.top.width = px(3),
    column_labels.border.top.color = "transparent",
    column_labels.border.bottom.width = px(3),
    column_labels.border.bottom.color = "black",
    data_row.padding = px(3),
    source_notes.font.size = 12,
    table.font.size = 16,
    heading.align = "left",
    ...
  ) 
}

options(gt.theme=gt_theme_538)

gt_t<-function(...) {
  thm <- options("gt.theme")$gt.theme
  if (is.null(thm)) {
    return(gt::gt(...))
  } else {
    return(gt::gt(...) %>% thm)
  }
}

ggplot_t <- function(...) {
  return( ggplot2::ggplot(...) + scale_fill_discrete() + scale_color_discrete())
}

gt<-gt_t
ggplot<-ggplot_t

```

```{r sec-3-publisher}

                                
journal_analysis.tbl  %>% gf_bar(~fct_infreq(CAT_PUBLISHER)) + aes(x=desc(CAT_PUBLISHER)) + coord_flip()  

```
# Sec 4.1 Ecosystem Characterization
## Table: Journal Characteristics by publisher and open status
```{r table-journal-publisher}

journal_analysis.tbl %>%
  unnest(LIST_SUBJECTS) %>% 
  group_by(CAT_PUBLISHER) %>% 
  summarize(n_journal=n(),
         p_oa = sum(IND_OPEN,na.rm=TRUE)/sum(!is.na(IND_OPEN)),
         p_top = sum(FAC_TOP>"no TOP")/sum(!is.na(FAC_TOP)),
         mn_boards_all = mean(N_JRN_SIZE,na.rm=TRUE),
         range_boards_all =paste((range(N_JRN_SIZE, na.rm=TRUE)),collapse="-")
  ) %>% gt_t() %>% 
    cols_label( "n_journal" = "# of journals",
                "CAT_PUBLISHER" ="",
                "p_oa"="% open access" , 
                "p_top"="% open science ",
                "mn_boards_all"="# members (mean)",
                "range_boards_all"="[Range]"
                ) %>%
    fmt_percent(columns=c("p_oa","p_top"),decimals=0) %>%
    fmt_number(columns=c("mn_boards_all"),decimals=1) %>%
    tab_header(title="Journal Characteristics") %>%
   # tab_source_note( source_note = "Note: Category membership overlaps -- a journals may be assigned up to three disciplines" ) %>%
    data_color (
      columns = vars(p_top,p_oa), 
      colors = scales::col_numeric( 
      palette = c( "white","orange"), 
        domain = c(0,1) ) 
    ) 

```

## Fig: Editor by country
```{r analysis-editors-map}


world.sf <- ne_countries(scale = "medium", returnclass = "sf")

#TODO: track country code non-matches "RE" "UK" "GP" "MQ" "GF" "XK" "AN"
ctry_totals<- editors_analysis.tbl %>% group_by(LS_COUNTRY) %>% summarise(n_editors=n()) %>% rename(iso_a2=LS_COUNTRY)

world.sf %<>% left_join(ctry_totals) 

ggplot(data = world.sf) + geom_sf(aes(fill = n_editors)) + scale_fill_continuous( trans = "log")

#TODO: Replace Desc with ggformula
editors_analysis.tbl %>% Desc(~LS_COUNTRY,data=.)

editors_analysis.tbl %<>% mutate(LS_COUNTRY_U = ifelse(is.na(LS_COUNTRY),"Unknown",LS_COUNTRY))

#TODO: Fix crosstable kludge -- cleaner with group_by?
  edcountry.ct <-  crosstable(editors_analysis.tbl, c(LS_COUNTRY_U), by=FAC_ROLE, margin="none", total="row", showNA="no") 
  
 edcountry.gt <- edcountry.ct %>% arrange(desc(as.numeric(Total))) %>% mutate(Percentage=0+as.numeric(Total)/sum(as.numeric(Total))) %>% slice_head(n=20) %>% crosstable::as_gt()
  edcountry.gt$"_data"$Percentage=as.numeric(edcountry.gt$"_data"$Percentage)
 
 
 edcountry.gt %>% 
    cols_label( "Percentage"="%", 
                ) %>%
    fmt_percent(columns=matches("Percentage"),decimals=0) %>%
    tab_header(title="Roles by Country") %>%
    data_color (
      columns = c("Percentage"), 
      colors = scales::col_numeric( 
      palette = c( "white","orange"), 
        domain = c(0,1) ) 
    ) %>% 
    gt_theme_538() 
  
```
## Fig: Editor by role and gender ; editor by role & country
```{r}
editors_analysis.tbl %>% mutate(IND_FEMALE=!IND_MALE) %>% gf_percents(~FAC_ROLE,fill=~IND_FEMALE)
editors_analysis.tbl %>% gf_percents(~FAC_ROLE,fill=~LS_COUNTRY)
   
```


### Fig: Board interconnectivity
```{r figure-interconnect}

journals.grViz <- journals_linked.graph %>% render_graph(output="visNetwork")

journals_linked.tgraph %>% ggraph(layout="stress") +
    geom_edge_fan(alpha=.2) +
    geom_node_point(aes(color=factor(CAT_PUBLISHER))) + scale_color_viridis_d()
  
```
# Sec 4.2 Correlates of Diversity
## Board Diversity by Role and discipline
```{r table-journal-discipline}

boardDiverse.tbl <-  journal_board_analysis.tbl %>%
  unnest(LIST_SUBJECTS) %>% 
  filter(!is.na(FAC_ROLE)) %>%
  group_by(LABEL_SUBJECT,FAC_ROLE) %>% 
  summarize(n_journal=n(),
         #male = mean(PERCENT_ROLEGROUP_MALE,na.rm=TRUE),
         male = mean(PROPENSITY_ROLEGROUP_MALE,na.rm=TRUE),
         international =  1-mean(PERCENT_HHI,na.rm=TRUE),
       
  ) %>%
  mutate(female=1-male) %>%
  ungroup %>% select(-male) %>%
  pivot_longer(cols=c(female,international),names_to="divtype",values_to="per") %>%
  mutate(LABEL_SUBJECT=replace_na(LABEL_SUBJECT,"Uncategorized")) 

boardDiverse.tbl %>%
   pivot_wider(id_cols="LABEL_SUBJECT",
              names_from=c(FAC_ROLE,divtype),values_from="per") %>%
  gt() %>% 
    cols_label( "LABEL_SUBJECT"="",
                "review_female"="Review board: % female" , 
                "review_international"="Review board: % national concentration",
                "editor_female"="Editorial board: % female" , 
                "editor_international"="Editorial board: % national concentration",
                "chief_female"="Chief editors: % female" , 
                "chief_international"="Chief editors: % national concentration",
                ) %>%
    fmt_percent(columns=matches("male|international"),decimals=0) %>%
    tab_header(title="Board Diversity by Role and Discipline") %>%
    tab_source_note( source_note = "Note: Disciplinary membership overlaps." ) %>%
    data_color (
      columns = matches("male|international"), 
      colors = scales::col_numeric( 
      palette = c( "white","orange"), 
        domain = c(0,1) ) 
    ) %>% 
    gt_theme_538() 

subj_order <-  boardDiverse.tbl %>%
  group_by(LABEL_SUBJECT) %>% mutate(subj_order=max(per[which(divtype=="female")],na.rm=TRUE)) %>%
  pull(subj_order)


okabe <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")


  boardDiverse.tbl %>%
    group_by(LABEL_SUBJECT) %>% 
    ggplot(aes(x= per,y=reorder(LABEL_SUBJECT,subj_order))) +
    geom_line(aes(group = LABEL_SUBJECT))+
    geom_point(aes(color=FAC_ROLE), size=4) +
    facet_wrap(facets=vars(divtype)) +
     labs(x = "Diversity", y="",
       title = "Board diversity by journal discipline and role",
       color = "Role") 




```
```{r}


editors_analysis.tbl %>% 
  filter(!is.na(FAC_ROLE)) %>%
  mutate(IND_TOP=(FAC_TOP>"no TOP")) %>%
  mutate(IND_TOP=ifelse(IND_TOP,"TOP Open Science","Not Open Science")) %>%
  group_by(IND_OPEN,FAC_ROLE,IND_TOP) %>%
  summarize(prop_male = mean(PERCENT_PROPENSITY_MALE,na.rm=TRUE)) %>%
  ungroup() %>%
  pivot_wider(values_from=prop_male, names_from=IND_OPEN) %>%
  group_by(IND_TOP) %>%
  gt() %>% 
    cols_label( "IND_TOP" = "Top Signatory",
                "FAC_ROLE"="",
                "FALSE"="Closed Access" , 
                "TRUE"="Open Access",
                ) %>%
    fmt_percent(columns=matches("FALSE|TRUE"),decimals=0) %>%
    tab_header(title="Editor Proportion Male by OA and TOPS status") %>%
    data_color (
      columns = matches("FALSE|TRUE"), 
      colors = scales::col_numeric( 
      palette = c( "white","orange"), 
        domain = c(0,1) ) 
    ) %>% 
    gt_theme_538() 

journal_board_analysis.tbl %>% 
  filter(!is.na(FAC_ROLE)) %>%
  mutate(IND_TOP=(FAC_TOP>"no TOP")) %>%
  mutate(IND_TOP=ifelse(IND_TOP,"TOP Open Science","Not Open Science")) %>%
  group_by(IND_OPEN,FAC_ROLE,IND_TOP) %>%
  summarize(prop_male = mean(PROPENSITY_ROLEGROUP_MALE,na.rm=TRUE)) %>%
  ungroup() %>%
  pivot_wider(values_from=prop_male, names_from=IND_OPEN) %>%
  group_by(IND_TOP) %>%
  gt() %>% 
    cols_label( "IND_TOP" = "Top Signatory",
                "FAC_ROLE"="",
                "FALSE"="Closed Access" , 
                "TRUE"="Open Access",
                ) %>%
    fmt_percent(columns=matches("FALSE|TRUE"),decimals=0) %>%
    tab_header(title="Board Proportion Male by OA and TOPS status") %>%
    data_color (
      columns = matches("FALSE|TRUE"), 
      colors = scales::col_numeric( 
      palette = c( "white","orange"), 
        domain = c(0,1) ) 
    ) %>% 
    gt_theme_538() 


journal_board_analysis.tbl %>% 
  filter(!is.na(FAC_ROLE)) %>%
  mutate(IND_TOP=(FAC_TOP>"no TOP")) %>%
  mutate(IND_TOP=ifelse(IND_TOP,"TOP Open Science","Not Open Science")) %>%
  group_by(IND_OPEN,FAC_ROLE,IND_TOP) %>%
  summarize( ihhi = 1-mean(PERCENT_HHI,na.rm=TRUE)) %>%
  ungroup() %>%
  pivot_wider(values_from=ihhi, names_from=IND_OPEN) %>%
  group_by(IND_TOP) %>%
  gt() %>% 
    cols_label( "IND_TOP" = "Top Signatory",
                "FAC_ROLE"="",
                "FALSE"="Closed Access" , 
                "TRUE"="Open Access",
                ) %>%
    fmt_percent(columns=matches("FALSE|TRUE"),decimals=0) %>%
    tab_header(title="Board International Diversity by OA and TOPS status") %>%
    data_color (
      columns = matches("FALSE|TRUE"), 
      colors = scales::col_numeric( 
      palette = c( "white","orange"), 
        domain = c(0,1) ) 
    ) %>% 
    gt_theme_538() 




```
```{r}

tmp <- journal_board_analysis.tbl %>% 
  filter(!is.na(FAC_ROLE)) %>%
  mutate(IND_TOP=(FAC_TOP>"no TOP"))
p1<- tmp %>% gf_dens2(~PERCENT_HHI|FAC_ROLE,fill=~IND_OPEN)
p2<- tmp %>% gf_dens2(~PERCENT_ROLEGROUP_MALE|FAC_ROLE,fill=~IND_OPEN)
p3<- tmp %>% gf_dens2(~PERCENT_HHI|FAC_ROLE,fill=~IND_TOP)
p4<- tmp %>% gf_dens2(~PERCENT_ROLEGROUP_MALE|FAC_ROLE,fill=~IND_TOP)
plot((p1+p2)/(p3+p4))

p1<- tmp %>% gf_dens2(~PERCENT_HHI|FAC_ROLE,fill=~IND_OPEN)
p2<- tmp %>% gf_dens2(~1-PROPENSITY_ROLEGROUP_MALE|FAC_ROLE,fill=~IND_OPEN)
p3<- tmp %>% gf_dens2(~PERCENT_HHI|FAC_ROLE,fill=~IND_TOP)
p4<- tmp %>% gf_dens2(~1-PROPENSITY_ROLEGROUP_MALE|FAC_ROLE,fill=~IND_TOP)
plot((p1+p2)/(p3+p4))
```


```{r multivariate}
lm.res <- journal_board_analysis.tbl %>% 
  lm(PERCENT_ROLEGROUP_MALE~IND_OPEN+FAC_TOP+FAC_ROLE+N_SUBJECTS,data=.)


lm.res %>% tidy() %>% gt()
lm.res %>% glance() %>% gt()
plot(lm.res)

lm.res <- journal_board_analysis.tbl %>% 
  lm(PROPENSITY_ROLEGROUP_MALE~IND_OPEN+FAC_TOP+FAC_ROLE+N_SUBJECTS,data=.)


lm.res %>% tidy() %>% gt()
lm.res %>% glance() %>% gt()
plot(lm.res)
```


```{r journal-cliques}

journals_linked.igraph<-as.igraph(journals_linked.tgraph)
jcomp.list <- decompose(journals_linked.igraph)
jcomp.tib.list <-jcomp.list %>% map(function(x)as.tibble(igraph::as_data_frame(x,what="vertices")))
jcomp.sizes<-jcomp.tib.list %>% map(nrow) 
jcomp.sizes %>% unlist %>%  as.tibble %>% group_by(value) %>%
  count %>% ungroup %>% pivot_wider(names_from=value,values_from=n) %>%
  gt %>% 
    tab_header(title="Distribution of Editorial Board Clusters") %>%
    gt_theme_538() 

clustjournals.tib <- jcomp.tib.list[which(jcomp.sizes>20)] %>% map_dfr(~.x)
clustjournals_all.tib <- jcomp.tib.list[which(jcomp.sizes>2)] %>% map_dfr(~.x)


clustjournals.tib %>%  count(CAT_PUBLISHER,IND_OPEN,IND_TOP=FAC_TOP>1,sort=TRUE) %>%
    gt %>% 
    tab_header(title="Composition of Large Clusters") %>%
    gt_theme_538()

clustjournals.tib %>% unnest(LIST_SUBJECTS) %>% count(LABEL_SUBJECT,sort=TRUE) %>%
    gt %>% 
    tab_header(title="Journal Subject of Large Clusters") %>%
    gt_theme_538()

clustjournals_all.tib %>% unnest(LIST_EDID) %>% count(LIST_EDID,sort=TRUE) %>%
   count(n) %>% 
   filter(n>1) %>% 
   gt %>% 
    cols_label(n="Number of journals",nn="") %>%
    tab_header(title="Number of journals served by repeat editors") %>%
    gt_theme_538()

clustjournals_all.tib %>% unnest(LIST_EDID) %>% count(LIST_EDID,sort=TRUE) %>%
   count(n) %>% 
   filter(n>1) %>% 
  summarize(n=sum(n))

# For each cluster
# Compute publisher, OA, OS status
# Avg board overlap
# Max linked individual
```  

```{r indiveditors}
multied.tib <- clustjournals_all.tib %>% 
  unnest(LIST_EDID) %>% 
  count(LIST_EDID,sort=TRUE) %>%
  filter(n>5) %>% 
  left_join(person_ids.tbl, by=c("LIST_EDID"="editor_id")) %>%
  left_join(editors_full.tbl) %>% relocate(CAT_ROLE,role)


multiedan.tib <- clustjournals_all.tib %>%   unnest(LIST_EDID) %>% 
  count(LIST_EDID,sort=TRUE) %>%
  filter(n>5) %>% 
  left_join(editors_analysis.tbl,by=c("LIST_EDID"="NM_EDID"))


  

emerald.tib <- editors_full.tbl %>% filter(str_detect(LS_INSTITUTION,"Emerald")) 
       
multied.tib
emerald.tib
```


# Supplementary Materials
# Exploratory 
## Ad-Hoc Exploration


##standardized exploratory check
```{r}
explore.ls <-  lapply(ls(pattern="_analysis.tbl"),sym)
```

```{r}
for (i in explore.ls) { cat("****\n"); print(i); cat("****\n"); print(skim(eval(i))) }
```

```{r}
library(DescTools)
for (i in explore.ls)
{ 
  cat("****\n");
  print(i); 
  cat("****\n");
  print(Desc(
      eval(i) %>% select(-starts_with("NM_"),-where(is.list))
             ))
  }
```

```{r}
library(corrr)

mixed_assoc = function(df, cor_method_numeric="pearson", cor_method_ordinal="kendall",
                       adjust_cramersv_bias=TRUE){
# Calculate a pairwise association between all variables in a data-frame. In particular nominal vs nominal with Chi-square, numeric vs numeric with Pearson correlation, and nominal vs numeric with ANOVA.
# Adopted from https://stackoverflow.com/a/52557631/590437
#  -- extended by Micah Altman to detect ordered factors, and to use DescTools rather than rcompanion
  
    df_comb = expand.grid(names(df), names(df),  stringsAsFactors = F) %>% set_names("X1", "X2")

    is_nominal = function(x) class(x) %in% c("factor", "character")
    # https://community.rstudio.com/t/why-is-purr-is-numeric-deprecated/3559
    # https://github.com/r-lib/rlang/issues/781
    is_numeric <- function(x) { is.integer(x) || is_double(x)}
    is_ordinal <- function(x) { is.ordered(x) || is_logical(x)}


    f = function(xName,yName) {
        x =  pull(df, xName)
        y =  pull(df, yName)

        result = if(is_nominal(x) && is_nominal(y)){
            # use bias corrected cramersV as described in https://rdrr.io/cran/rcompanion/man/cramerV.html
            cv = CramerV(as.character(x), as.character(y), correct= adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")

        }else if(is_numeric(x) && is_numeric(y)){
            correlation = cor(x, y, method=cor_method_numeric, use="na.or.complete")
            data.frame(xName, yName, assoc=correlation, type=cor_method_numeric)

        }else if(is_numeric(x) && is_nominal(y)){
            # from https://stats.stackexchange.com/questions/119835/correlation-between-a-nominal-iv-and-a-continuous-dv-variable/124618#124618
            r_squared = summary(lm(x ~ y))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")
        }else if(is_nominal(x) && is_numeric(y)){
            r_squared = summary(lm(y ~x))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")

       } else if(is_ordinal(x) && is_ordinal(y)){
            correlation = cor(as.integer(x), as.integer(y), method=cor_method_ordinal, use="na.or.complete")
            data.frame(xName, yName, assoc=correlation, type=cor_method_ordinal)
       }else if(is_ordinal(x) && is_numeric(y)){
            r_squared = summary(lm(y ~ x))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")
       }else if(is_numeric(x) && is_ordinal(y)){
            r_squared = summary(lm(x ~ y))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")
       }else if(is_nominal(x) && is_ordinal(y)){

            cv = CramerV(as.character(x), as.character(y), correct= adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")
       }else if(is_ordinal(x) && is_nominal(y)){

            cv = CramerV(as.character(x), as.character(y), correct= adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")
    
        } else {
            warn(paste("unmatched column type combination: ", class(x), class(y)))
            return(NULL)
        }

        # finally add complete obs number and ratio to table
        result %>% mutate(complete_obs_pairs=sum(!is.na(x) & !is.na(y)), complete_obs_ratio=complete_obs_pairs/length(x)) %>% rename(x=xName, y=yName)
    }

    # apply function to each variable combination
    map2_df(df_comb$X1, df_comb$X2, f)
}
```

```{r}
for (i in explore.ls) { 
  cat("****\n"); 
  print(i); 
  cat("****\n");


assoc.tbl <- eval(i) %>%
   select(-starts_with("NM_"), -starts_with("LIST_"),-where(is.list))%>%
   slice_sample(n=1000) %>%
    mixed_assoc(df=.) 

print(assoc.tbl)


try ({
  assoc.tbl %>%
    select(x, y, assoc) %>%
    na.omit %>%
    spread(y, assoc) %>%
    column_to_rownames("x") %>%
    na.omit %>%
    as.matrix %>%
    as_cordf %>%
    network_plot() %>% print
  })
}
```

