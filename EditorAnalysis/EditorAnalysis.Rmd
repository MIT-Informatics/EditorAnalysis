---
title: Replication for ...
bibliography: mybibfile.bib
output: 
  html_document:
    toc: yes
    toc_depth: 2
    number_section: yes
    theme: journal
    highlight: zenburn
    code_folding: hide
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  rticles::plos_article:
    csl: plos.csl
params:
  doc_refresh_data:
    value: no
    choices:
    - yes
    - no
  doc_debug:
    value: no
    choices:
    - yes
    - no
editor_options: 
  markdown: 
    wrap: 72
---

```{r label=setup, include=FALSE}
library(knitr)
## options for this document
doc_debug <- params$doc_debug
doc_refresh_data <- params$doc_refresh_data
knitr::opts_chunk$set("message" = doc_debug)
knitr::opts_chunk$set("warning" = doc_debug)
knitr::opts_chunk$set("tidy" = FALSE) # already tidyed using stylr
knitr::opts_chunk$set(autodep=TRUE)

## check for webshot if pdf output
doc_is_pdf <- 
  try (("pdf_document" %in% rmarkdown::all_output_formats(knitr::current_input())), silent=TRUE)
doc_is_pdf <- (doc_is_pdf == TRUE)
if (doc_is_pdf) {
  require("webshot")
  webshot::install_phantomjs()
}
# works in knit, but not in other environments
try(knitr::dep_auto())
```

```{r r-setup, include=FALSE}
# core libraries
library("tidyverse")
library("magrittr")
library("rlang")
library("purrr")
if (doc_debug) {
  require("tidylog")
}
library("gt")
library("ggplot2")
library("patchwork")

# data retrieval
library("R.utils")
library("readxl")
library("fuzzyjoin")

# entity extraction and classification
library("humaniformat") # for first name extraction
library("gender")
library("genderdata") # install using devtools::install_github("lmullen/genderdata")
library("reticulate") # python geoentity extraction

# analysis
library("skimr")
library("ggspatial") # needs libudunits2-dev -- sudo apt-get install libudunits2-dev
                     # sudo apt-get install gdal-bin proj-bin libgdal-dev libproj-dev
library("rnaturalearth")
library("rnaturalearthdata")
library("DescTools")
```
```{r fetch-data, include=FALSE}
###
### Retrieve raw data from sources
### 


##
## OpenEditors Data
## 

db.name <- "openeditors_combined.csv"
if (doc_refresh_data) {
  
   uris <- c(editor1.csv ="https://raw.githubusercontent.com/andreaspacher/openeditors/main/Output/editors1.csv",
            editor2.csv= "https://raw.githubusercontent.com/andreaspacher/openeditors/main/Output/editors2.csv")
   
   tmp.tbl <- NULL
   
   tmpfile <- tempfile(fileext=".csv")

   for (j in 1:length(uris)) {
     i <- uris[j]
     download.file(i,names(i))
     gEnc <- guess_encoding(names(i),n_max=-1)[[1]] # originally tried alternative encodings such as windows-1250, latin1, UTF8, "ISO-8859-1" as encodings,
     tmp.tbl %<>% bind_rows(read_csv(names(i),  locale = readr::locale(encoding = gEnc)))
   }
   write_csv(tmp.tbl,db.name)
   gzip(db.name)
}

editors_raw.tbl <- read_csv(paste(db.name,".gz",sep=""))


##
## DOAJ
##

db.name <- "doaj.csv"
if (doc_refresh_data) {
   download.file("https://doaj.org/csv",db.name)
   gzip(db.name)
}

doaj_raw.tbl <- read_csv(paste(db.name,".gz",sep=""))


##
## ERA
## 


db.name <- "era.xlsx" 
# linked from: "https://www.arc.gov.au/excellence-research-australia/era-2018-journal-list"
if (doc_refresh_data) {
  download.file("https://www.arc.gov.au/file/10549/download?token=Sbfb2a9n",db.name)
}
era_raw.tbl <- read_excel(db.name,2)
fieldcode_raw.tbl <- read_excel(db.name,3)
rm(db.name)
```


```{r data-tops-fetch}
##
## TOPS
## 

target.uri <- "https://osf.io/qatkz/download"
db.name <- "tops_factor_raw.csv" 
if (doc_refresh_data) {
  download.file(target.uri,db.name)
}
tops_factor_raw.tbl <- read_csv(db.name)
target.uri <- "https://osf.io/y2rr6/download"
db.name <- "tops_signatory.csv" 
if (doc_refresh_data) {
  download.file(target.uri,db.name)
}
tops_signatory_raw.tbl <- read_csv(db.name)
rm(db.name,target.uri)
```

```{r data-clean, include=FALSE}
### DOAJ
### normalize issn fields in preparation for merging
doaj.tbl <- doaj_raw.tbl
doaj.tbl %<>% pivot_longer(cols=c("Journal ISSN (print version)","Journal EISSN (online version)"),
                           values_to ="issn", names_to ="issn_type ", values_drop_na=TRUE)
# NOTE -- checked that LICENSE, LCC not missing

### ERA
### normalize by issn, pack subject field
era.tbl <- era_raw.tbl
era.tbl %<>% select(-c(starts_with("ERA"), ends_with("Name"), starts_with("Foreign")))
era.tbl %<>% unite("subjects",starts_with("FoR"),sep=",",na.rm=TRUE) %>%
  pivot_longer(starts_with("ISSN"), names_to = NULL, values_to = "issn", values_drop_na = TRUE ) %>% rename(journal="Title")

###
### Editors cleanup
editors_clean.tbl <- editors_raw.tbl
editors_clean.tbl %<>% select(-X1) 
editors_clean.tbl %<>% mutate(across(-c("issn","date","url"),as_utf8_character)) # clean unicode sequences
editors_clean.tbl %<>% mutate(across(-c("issn","date","url"),function(x)str_replace_all(x,'\\<.*\\>',''))) # strip unresolved escapes 
#TODO: convert latin-1 escape sequences to Unicode rather than strip them)
editors_clean.tbl %<>%
mutate(across(-c("issn","date","url"),str_squish)) # clean unicode sequences

# Some journals missing ISSN code, match against other sources by name & publisher to find ISSN
era_issn.tbl <-  era.tbl %>% select("issn","journal") %>% group_by(journal) %>% slice_head(n=1) %>% rowwise() %>% mutate(
  journalStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " "))))
) %>% ungroup() %>% select(-journal)

noissn.tbl <- editors_clean.tbl %>% 
  filter(issn=="") %>% select(c("journal","publisher")) %>% 
  mutate(
  journalStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " "))))
) %>% ungroup()
duplicate_journals <- noissn.tbl %>% group_by(journalStd,publisher) %>% count() %>% group_by(journalStd) %>% count() %>% filter(n>1)

if (nrow(duplicate_journals>0))  { 
  warn("duplicate journal names")
  noissn.tbl %<>% group_by(journalStd) %>% slice_head(n=1) %>% ungroup()
}

noissn.tbl %<>% left_join( era_issn.tbl , by=c("journalStd")) 
joinedissn.tbl <- noissn.tbl %>% filter(!is.na(issn))
noissn.tbl %<>% filter(is.na(issn)) %>% select(-issn)

joinedissn.tbl %<>% group_by(`journal`) %>% slice_head(n=1)  %>% select("publisher","issn")

editors_clean.tbl %<>% left_join(joinedissn.tbl,by=c("publisher","journal")) %>% unite("issn","issn.x","issn.y",na.rm=TRUE)


# fuzzy matching on remaining journals

matches.tbl <- noissn.tbl %>% stringdist_left_join( 
  era_issn.tbl ,
  by=c("journalStd"), 
  ignore_case=TRUE,
  distance_col="dist",
  max_dist=3
  ) %>% 
  filter(!issn=="") %>% 
  mutate(len=str_length(journalStd.x),distp=(len-dist)/len) %>% arrange(desc(distp)) %>%
  group_by(journal) %>%
  slice_max(distp) %>% 
  slice_head() %>% 
  filter(distp >= .95)

matches.tbl %<>% select(journal,issn,publisher)

editors_clean.tbl %<>% 
  left_join(matches.tbl,by=c("publisher","journal")) %>%
  unite("issn","issn.x","issn.y",na.rm=TRUE)

rm(joinedissn.tbl.tbl,duplicate_journals, matches.tbl)
```

```{r tops-clean}

### clean tops data

tops_factor_clean.tbl <- tops_factor_raw.tbl %>%
  select(Journal, Issn, Publisher, Total) %>%
  rename(journal=Journal,issn=Issn,topScore=Total) %>% mutate(
    journalStd = str_to_lower(str_squish((str_replace_all(journal, regex("\\W+"), " "))))
  )

matches.tbl <- tops_factor_clean.tbl %>% filter(is.na(issn)) %>% select(journalStd) %>% left_join(era_issn.tbl,by=("journalStd")) %>% filter(!is.na(issn))

tops_factor_clean.tbl %<>% left_join(matches.tbl, by=("journalStd")) %>%
    unite("issn","issn.x","issn.y",na.rm=TRUE) %>% filter(!is.na(issn)) %>% 
    group_by(issn) %>% slice_head()

```


```{r data-merge}
### Join editors with journal information
editors_join.tbl <- editors_clean.tbl

if (!doc_debug) {
    #rm("editors_raw.tbl","era_raw.tbl")
}
editors_join.tbl %<>% left_join(doaj.tbl %>% select(issn,"Journal license"), by="issn") %>% rename(license="Journal license")  %>% rowwise() %>%  mutate(license = ifelse(is.na(license),"none",license),  IND_openlicense=(license!="none"))

editors_join.tbl %<>% mutate(IND_openlicense = ifelse(issn=="",NA,IND_openlicense))

editors_join.tbl %<>% left_join(era.tbl %>% select(issn,subjects), by=c("issn"))
editors_join.tbl %<>% left_join(tops_factor_clean.tbl %>% select(issn,topScore) %>% filter(!is.na(issn)),by=c("issn")) 
editors_join.tbl %<>% rowwise() %>% mutate(topScoreAdj = ifelse(is.na(topScore),0,topScore+1)) %>% select(-topScore)


```

-   Fields parsed
-   first name: extracted from full name (using humaniformat), with
    preprocessing to remove titled ("Dr.","Professor.")
-   county - parsed from affiliation, validated with gazetteer

```{r data-parse-names}
### extract given names for gender analysis
editors_parse.tbl <- editors_join.tbl 
if (!doc_debug) {
    rm("editors_clean.tbl")
}

# first_name() fails on empty string, wrap it
safe_first_name <- possibly(first_name, otherwise="")

# remove honorifics
editors_parse.tbl %<>% rowwise() %>% mutate( LS_FULLNAME = str_squish(str_replace( `editor`, '(Dr\\.)|(Prof\\.)|(Doctor)|(Professor)|(Dr )|(Prof )', '')))                                    
editors_parse.tbl %<>% rowwise() %>% mutate(LS_GIVENNAME = safe_first_name(`LS_FULLNAME`))
                                             
                 
#post-cleanup
# single letter, or ending with a period of comma, is a last name, or abbreviation rather than first
editors_parse.tbl %<>% rowwise() %>% mutate(LS_GIVENNAME = case_when(
  LS_GIVENNAME=="" ~ NA_character_,
  str_length(LS_GIVENNAME)==1 ~ NA_character_,
  str_detect(LS_GIVENNAME,'.*(\\.|\\,)') ~ NA_character_,
  TRUE ~ LS_GIVENNAME
))
```

```{r data-parse-countries}
### extract country using geotext
editors_parse_c.tbl <- editors_parse.tbl 
if (!doc_debug) {
    rm("editors_join.tbl")
}

## setup geotext
if (doc_refresh_data & doc_debug) {
  py_install(packages="geotext") 
}

wrap_python <- function (module,importfun) {
  core_fun <- import(module)
  safe_fun <- possibly(core_fun[importfun], otherwise=NA)
  safe_list_fun <- function (xlist,...) {
    return( 
      sapply(xlist, safe_fun, ...,
             simplify=TRUE, USE.NAMES=FALSE )
    )
  }
}

geotext<- wrap_python("geotext","GeoText") 

## geotext and check against naive parsing

affiliations.tbl <- editors_parse_c.tbl %>% group_by(`affiliation`) %>% slice_head(n=1) %>% ungroup() %>% select(`affiliation`)

affiliations.tbl %<>% rowwise() %>% mutate(LS_COUNTRY_CHK = tail(unlist(str_split(`affiliation`,',')),n=1))

affiliations.tbl %<>% rowwise() %>% mutate( 
  LS_COUNTRY_G = names(geotext(str_to_title(`LS_COUNTRY_CHK`))[[1]]["country_mentions"])[1] 
  )

affiliations.tbl %<>% rowwise() %>% mutate(LS_COUNTRY_CHK2 = str_to_title(LS_COUNTRY_CHK),
          LS_COUNTRY = case_when(
  !is.na(LS_COUNTRY_G) ~ LS_COUNTRY_G, 
  str_detect(LS_COUNTRY_CHK,"USA") ~ "US",
  str_detect(LS_COUNTRY_CHK,"UK") ~ "GB",
  str_detect(LS_COUNTRY_CHK2,"Netherlands") ~ "NL",
  str_detect(LS_COUNTRY_CHK2,"Russia") ~ "RU",
  str_detect(LS_COUNTRY_CHK2,"Viet Nam") ~ "VN",
  str_detect(LS_COUNTRY_CHK2,"Korea") ~ "KR",
  str_detect(LS_COUNTRY_CHK2,"Emirates") ~ "AE",
  str_detect(LS_COUNTRY_CHK,"UAE") ~ "AE",
  str_detect(LS_COUNTRY_CHK,"CHN") ~ "CN",
  str_detect(LS_COUNTRY_CHK2,"Brasil") ~ "BR",
  str_detect(LS_COUNTRY_CHK2,"Scotland") ~ "GB",
  str_detect(LS_COUNTRY_CHK2,"Singapore") ~ "SG",
  str_detect(LS_COUNTRY_CHK2,"Trinidad") ~ "TT",
  str_detect(LS_COUNTRY_CHK,"KSA") ~ "SA",
  str_detect(affiliation,"Korea") ~ "KR",
  TRUE ~ ""
))

editors_parse_c.tbl %<>% left_join(affiliations.tbl  %>% select("affiliation","LS_COUNTRY"), by=c("affiliation"))
```

# Methods

## Gender Imputation



    ```{r code-roles}
    editors_full.tbl <- editors_parse_c.tbl
    if (!doc_debug) {
        rm("editors_parse.tbl")
    }

    ## role coding
    role.tbl <- editors_full.tbl %>% select(`role`) %>%  group_by(role) %>% count()  %>% mutate (`rolec`=str_to_title(role))

    role.tbl %<>% rowwise() %>%
    mutate(CAT_ROLE_FORMER = str_detect(rolec,'(Former)|(Past)|(Emerit)'))

    role.tbl %<>% rowwise() %>%
      mutate(CAT_ROLE = case_when(
        is.na(rolec) ~ "",
      str_detect(rolec,"(In Chief)|(In-Chief)") ~ "chief",
      str_detect(rolec,"Founding Editor") ~ "chief",
      str_detect(rolec,"Associate Editor") ~ "editor",
      str_detect(rolec,"Assistant Editor") ~ "editor",
      str_detect(rolec,"Senior Editor") ~ "editor",
      str_detect(rolec,"Book Review") ~ "editor",
      str_detect(rolec,"Academic Editor") ~ "review",
      str_detect(rolec,"Review Editor") ~ "review",
      str_detect(rolec,"Editorial Board") ~ "review",
      str_detect(rolec,"Advisory Board") ~ "review",
      str_detect(rolec,"Advisory Committee") ~ "review",
        str_detect(rolec,"Scientific Committee") ~ "review",
      str_detect(rolec,"Scientific Advisor") ~ "review",
      str_detect(rolec,"Editor") ~ "editor",
        str_detect(rolec,"Advisory") ~ "review",
      str_detect(rolec,"Review") ~ "review",
      str_detect(rolec,"Board") ~ "review",
      str_detect(rolec,"Academic") ~ "review",
      str_detect(rolec,"Members") ~ "review",
      TRUE ~ ""
    ))

    editors_full.tbl %<>% left_join(role.tbl %>% select(role,CAT_ROLE,CAT_ROLE_FORMER),by=c("role"))
    rm(role.tbl)
    ```

```{r gender_imputation, cache=TRUE, dependson=knitr::dep_auto()}
### impute gender based on name
gender_meth <- "ipums"
#TODO: 
# - multiple methods analysis
# - fix genderizer timeouts

# gender can fail on genderize method

safer_gender <- function(x,...) {
  safe_gender <- possibly(gender, otherwise=list(gender=""))
  rv <- safe_gender(x,...)[["gender"]]
  if (is.na(rv) || (length(rv)==0)) {
    rv <- ""
  }
  rv
}

nms.tbl <-  editors_full.tbl %>% count(`LS_GIVENNAME`) %>% arrange(desc(n))

nms.tbl %<>% rowwise() %>%
  mutate( LS_GENDER = 
           safer_gender(`LS_GIVENNAME`,method=gender_meth))

editors_full.tbl %<>% left_join(nms.tbl %>% select(-n), by=c("LS_GIVENNAME"))
edcsv.file <- "editors_full.csv.gz"
write_csv(editors_full.tbl,edcsv.file)
```

# Analysis

```{r analysis-prep}
if (!doc_debug) {
    rm("editors_parse_c.tbl")
}

if ( doc_debug ) {
    editors_full.tbl <- read_csv(edcsv.file,
                             col_types =list(subjects=col_character()) )
}

editors_analysis.tbl <- editors_full.tbl
editors_analysis.tbl %<>% mutate (
  FAC_ROLE = factor(CAT_ROLE, levels=c("review","editor","chief"), ordered=TRUE ),
  IND_MALE = na_if(LS_GENDER,"either"),
  IND_MALE = na_if(IND_MALE,""),
  IND_MALE = IND_MALE=="male",
  ) %>% 
  rename( NM_JOURNAL=journal, CAT_PUBLISHER=publisher, LS_SUBJECTS = subjects, IND_OPEN = IND_openlicense) %>%
  select(NM_JOURNAL, CAT_PUBLISHER, IND_MALE, IND_OPEN, LS_COUNTRY, LS_SUBJECTS, FAC_ROLE) %>% ungroup()

### construct editorial board characteristics
journal_board_analysis.tbl <- editors_analysis.tbl %>% 
  group_by(NM_JOURNAL,FAC_ROLE) %>% 
  summarise(
    CAT_PUBLISHER = head(CAT_PUBLISHER,n=1),
    LIST_SUBJECTS = unique(str_split(head(LS_SUBJECTS,n=1),',')),
    N_SUBJECTS = ifelse(head(LS_SUBJECTS,n=1)=="MD", 4, length(unlist(LIST_SUBJECTS))), # ERA counts 3 subjects, plus "MD" for multidisciplinary 
  IND_OPEN= head(IND_OPEN,n=1),
  LIST_ROLEGROUP_COUNTRIES = list(na.omit(LS_COUNTRY)),
  N_ROLEGROUP_COUNTRIES= length(unique(unlist(LIST_ROLEGROUP_COUNTRIES))),
  N_ROLEGROUP_COUNTRIES = na_if(N_ROLEGROUP_COUNTRIES,0),
  PERCENT_ROLEGROUP_MALE = mean(IND_MALE,na.rm=TRUE)
) %>% ungroup()

journal_analysis.tbl <- journal_board_analysis.tbl %>%
  group_by(NM_JOURNAL) %>%
  select(-N_ROLEGROUP_COUNTRIES,-PERCENT_ROLEGROUP_MALE, - LIST_ROLEGROUP_COUNTRIES) %>% 
  slice_head(n=1) %>% ungroup() %>% select(-NM_JOURNAL)
  
```

## Journal Characteristics

```{r analysis-descriptive-journal}
journal_analysis.tbl %>% select(-LIST_SUBJECTS) %>% Desc()
```

## Editor Characteristics

```{r analysis-descriptive-editorial-1}
editors_analysis.tbl  %>% Desc(formula=~IND_MALE+LS_COUNTRY+FAC_ROLE+IND_OPEN,data=.)
editors_analysis.tbl  %>% Desc(formula=LS_COUNTRY+FAC_ROLE+IND_MALE~IND_OPEN,data=.)
editors_analysis.tbl  %>% Desc(formula=IND_OPEN+FAC_ROLE+IND_OPEN %in% FAC_ROLE ~ IND_MALE,data=.)
```

```{r analysis-editors-map}
world.sf <- ne_countries(scale = "medium", returnclass = "sf")

# Todo: track country code non-matches "RE" "UK" "GP" "MQ" "GF" "XK" "AN"
ctry_totals<- editors_analysis.tbl %>% group_by(LS_COUNTRY) %>% summarise(n_editors=n()) %>% rename(iso_a2=LS_COUNTRY)

world.sf %<>% left_join(ctry_totals)

ggplot(data = world.sf) +
    geom_sf(aes(fill = n_editors)) +
        scale_fill_viridis_c(option = "E", trans = "log")
```

```{r analysis-edboards}


journal_board_analysis.tbl %>% select(-NM_JOURNAL,-LIST_ROLEGROUP_COUNTRIES,-LIST_SUBJECTS) %>% Desc(~.,data=.)
p1<-journal_board_analysis.tbl %>%
  filter(IND_OPEN) %>%
  Desc(FAC_ROLE~PERCENT_ROLEGROUP_MALE,data=.)

p2<- journal_board_analysis.tbl %>%
  filter(!IND_OPEN) %>%
  Desc(FAC_ROLE~PERCENT_ROLEGROUP_MALE,data=.)

plot(p1)
plot(p2)

journal_board_analysis.tbl %>%
  Desc(IND_OPEN~N_ROLEGROUP_COUNTRIES+PERCENT_ROLEGROUP_MALE+N_SUBJECTS,data=.)

journal_board_analysis.tbl %>%
  Desc(IND_OPEN~N_ROLEGROUP_COUNTRIES+PERCENT_ROLEGROUP_MALE+N_SUBJECTS,data=.)

journal_board_analysis.tbl %>%
  filter(FAC_ROLE=="chief") %>%
  Desc(IND_OPEN~N_ROLEGROUP_COUNTRIES+PERCENT_ROLEGROUP_MALE+N_SUBJECTS,data=.)
journal_board_analysis.tbl %>%
  filter(FAC_ROLE=="editor") %>%
  Desc(IND_OPEN~N_ROLEGROUP_COUNTRIES+PERCENT_ROLEGROUP_MALE+N_SUBJECTS,data=.)
journal_board_analysis.tbl %>%
  filter(FAC_ROLE=="review") %>%
  Desc(IND_OPEN~N_ROLEGROUP_COUNTRIES+PERCENT_ROLEGROUP_MALE+N_SUBJECTS,data=.)



#  Countries & Gender by Discipline

subject.tbl <- journal_board_analysis.tbl %>%
  unnest(LIST_SUBJECTS) %>% 
  rename(CAT_SUBJECT=LIST_SUBJECTS) %>% 
  mutate(CAT_MAJSUBJECT=substr(CAT_SUBJECT,1,2)) %>%
  group_by(CAT_MAJSUBJECT,FAC_ROLE) %>% 
  summarize(AVG_SUBJROLE_MALE=mean(PERCENT_ROLEGROUP_MALE,na.rm=TRUE),
            AVG_SUBJROLE_COUNTRIES= mean(N_ROLEGROUP_COUNTRIES,na.rm=TRUE)) %>%
  left_join(fieldcode_raw.tbl,by=c(CAT_MAJSUBJECT="FoR Code")) %>% 
  rename(LABEL_SUBJECT="FoR Description") %>% ungroup() %>%
  mutate(LABEL_SUBJECT= ifelse(str_starts(CAT_MAJSUBJECT,"MD"),"Multidisciplinary",LABEL_SUBJECT))


subject.tbl %>% filter(FAC_ROLE=="editor") %>% arrange(AVG_SUBJROLE_MALE) %>%
  select(AVG_SUBJROLE_MALE,LABEL_SUBJECT) %>% gt()

subject.tbl %>% filter(FAC_ROLE=="editor") %>% arrange(desc(AVG_SUBJROLE_COUNTRIES)) %>%
  select(AVG_SUBJROLE_COUNTRIES,LABEL_SUBJECT) %>% gt()

lm.res <- journal_board_analysis.tbl %>% 
  lm(PERCENT_ROLEGROUP_MALE~IND_OPEN+FAC_ROLE+N_SUBJECTS,data=.)

summary(lm.res)
plot(lm.res)


```

# Results

-   Journal: field, OA status
-   Authors: 

# Discussion 
# References {\#references .unnumbered} 
# Appendix - Supplementary Tables 
# Exploratory Analysis -- Not For Submission

```{r}
explore.ls <-  lapply(ls(pattern="_analysis.tbl"),sym)
```

```{r}
library(skimr)
for (i in explore.ls) { cat("****\n"); print(i); cat("****\n"); print(skim(eval(i))) }
```

```{r}
library(DescTools)
#journal_analysis.tbl %>% select(-NM_JOURNAL) %>% Desc()
for (i in explore.ls)
{ 
  cat("****\n");
  print(i); 
  cat("****\n");
  print(Desc(
      eval(i) %>% select(-starts_with("NM_"),-where(is.list))
             ))
  }
```

```{r}
library(corrr)

mixed_assoc = function(df, cor_method_numeric="pearson", cor_method_ordinal="kendall",
                       adjust_cramersv_bias=TRUE){
# Calculate a pairwise association between all variables in a data-frame. In particular nominal vs nominal with Chi-square, numeric vs numeric with Pearson correlation, and nominal vs numeric with ANOVA.
# Adopted from https://stackoverflow.com/a/52557631/590437
#  -- extended by Micah Altman to detect ordered factors, and to use DescTools rather than rcompanion
  
    df_comb = expand.grid(names(df), names(df),  stringsAsFactors = F) %>% set_names("X1", "X2")

    is_nominal = function(x) class(x) %in% c("factor", "character")
    # https://community.rstudio.com/t/why-is-purr-is-numeric-deprecated/3559
    # https://github.com/r-lib/rlang/issues/781
    is_numeric <- function(x) { is.integer(x) || is_double(x)}
    is_ordinal <- function(x) { is.ordered(x) || is_logical(x)}


    f = function(xName,yName) {
        x =  pull(df, xName)
        y =  pull(df, yName)

        result = if(is_nominal(x) && is_nominal(y)){
            # use bias corrected cramersV as described in https://rdrr.io/cran/rcompanion/man/cramerV.html
            cv = CramerV(as.character(x), as.character(y), correct= adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")

        }else if(is_numeric(x) && is_numeric(y)){
            correlation = cor(x, y, method=cor_method_numeric, use="na.or.complete")
            data.frame(xName, yName, assoc=correlation, type=cor_method_numeric)

        }else if(is_numeric(x) && is_nominal(y)){
            # from https://stats.stackexchange.com/questions/119835/correlation-between-a-nominal-iv-and-a-continuous-dv-variable/124618#124618
            r_squared = summary(lm(x ~ y))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")
        }else if(is_nominal(x) && is_numeric(y)){
            r_squared = summary(lm(y ~x))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")

       } else if(is_ordinal(x) && is_ordinal(y)){
            correlation = cor(as.integer(x), as.integer(y), method=cor_method_ordinal, use="na.or.complete")
            data.frame(xName, yName, assoc=correlation, type=cor_method_ordinal)
       }else if(is_ordinal(x) && is_numeric(y)){
            r_squared = summary(lm(y ~ x))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")
       }else if(is_numeric(x) && is_ordinal(y)){
            r_squared = summary(lm(x ~ y))$r.squared
            data.frame(xName, yName, assoc=sqrt(r_squared), type="rsq")
       }else if(is_nominal(x) && is_ordinal(y)){

            cv = CramerV(as.character(x), as.character(y), correct= adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")
       }else if(is_ordinal(x) && is_nominal(y)){

            cv = CramerV(as.character(x), as.character(y), correct= adjust_cramersv_bias)
            data.frame(xName, yName, assoc=cv, type="cramersV")
    
        } else {
            warn(paste("unmatched column type combination: ", class(x), class(y)))
            return(NULL)
        }

        # finally add complete obs number and ratio to table
        result %>% mutate(complete_obs_pairs=sum(!is.na(x) & !is.na(y)), complete_obs_ratio=complete_obs_pairs/length(x)) %>% rename(x=xName, y=yName)
    }

    # apply function to each variable combination
    map2_df(df_comb$X1, df_comb$X2, f)
}
```

```{r}
for (i in explore.ls) { 
  cat("****\n"); 
  print(i); 
  cat("****\n");


assoc.tbl <- eval(i) %>%
   select(-starts_with("NM_"),-where(is.list))%>%
   slice_sample(n=1000) %>%
    mixed_assoc(df=.) 

print(assoc.tbl)

try ({assoc.tbl %>%
    select(x, y, assoc) %>%
    na.omit %>%
    spread(y, assoc) %>%
    column_to_rownames("x") %>%
    as.matrix %>%
    as_cordf %>%
    network_plot() %>% print})
}
```

```{r}
library(brinton)

if (interactive()) {
  for (i in explore.ls)
  { 
  cat("****\n");
  print(i); 
  cat("****\n");
  tmp <- eval(i) %>%
    select(-starts_with("NM_"),-where(is.list)) %>%
    as_data_frame %>% as.data.frame
  }
  try({wideplot(tmp,dir=".")})
}
```